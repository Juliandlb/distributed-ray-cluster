apiVersion: v1
kind: ConfigMap
metadata:
  name: ray-config
  namespace: ray-cluster
data:
  head_config.yaml: |
    ray:
      head:
        port: 6379
        dashboard_port: 8265
        object_store_memory: 500000000
        num_cpus: 2
        temp_dir: /tmp/ray
        include_dashboard: true
        log_to_driver: true
        logging_level: INFO
        # Bind to all interfaces for multi-machine communication
        address: 0.0.0.0
      
      cluster:
        max_workers: 10
        auto_scaling: true
        min_workers: 1
        
      resources:
        memory: 2000000000
        cpu: 2
        gpu: 0

    models:
      preload: ["tiny-gpt2"]
      cache_dir: "/app/models"

    logging:
      level: INFO
      format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

  worker_config.yaml: |
    ray:
      worker:
        # Use Kubernetes service discovery - works across machines
        head_address: ray-head-service.ray-cluster.svc.cluster.local:6379
        port: 0
        object_store_memory: 500000000
        num_cpus: 2
        num_gpus: ${CUDA_VISIBLE_DEVICES:-0}
        temp_dir: /tmp/ray
        log_to_driver: false
        logging_level: INFO
        
      resources:
        memory: 2000000000
        cpu: 2
        gpu: ${CUDA_VISIBLE_DEVICES:-0}

    models:
      preload: ["tiny-gpt2"]
      cache_dir: "/app/models"
      auto_load: true

    worker:
      join_timeout: 300
      retry_interval: 10
      max_retries: 30

    logging:
      level: INFO
      format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s" 