ray:
  worker:
    head_address: ${RAY_HEAD_ADDRESS}
    port: 0  # Auto-assign
    object_store_memory: 200000000  # 200MB (reduced from 500MB)
    num_cpus: 1  # Reduced from 2
    num_gpus: ${CUDA_VISIBLE_DEVICES:-0}
    temp_dir: /tmp/ray
    log_to_driver: false
    logging_level: INFO
    
  resources:
    memory: 1000000000  # 1GB (reduced from 2GB)
    cpu: 1  # Reduced from 2
    gpu: ${CUDA_VISIBLE_DEVICES:-0}

models:
  preload: ["tiny-gpt2"]  # Only load the smallest model
  cache_dir: "/app/models"
  auto_load: true

worker:
  join_timeout: 300  # 5 minutes
  retry_interval: 10  # 10 seconds
  max_retries: 30

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s" 