ray:
  worker:
    head_address: ${RAY_HEAD_ADDRESS}
    port: 0  # Auto-assign
    object_store_memory: 500000000  # 500MB (reduced from 1GB)
    num_cpus: 2  # Reduced from 4
    num_gpus: ${CUDA_VISIBLE_DEVICES:-0}
    temp_dir: /tmp/ray
    log_to_driver: false
    logging_level: INFO
    
  resources:
    memory: 2000000000  # 2GB (reduced from 4GB)
    cpu: 2  # Reduced from 4
    gpu: ${CUDA_VISIBLE_DEVICES:-0}

models:
  preload: ["tiny-gpt2"]  # Only load the smallest model
  cache_dir: "/app/models"
  auto_load: true

worker:
  join_timeout: 300  # 5 minutes
  retry_interval: 10  # 10 seconds
  max_retries: 30

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s" 