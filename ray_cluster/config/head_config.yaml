ray:
  head:
    port: 6379
    dashboard_port: 8265
    object_store_memory: 500000000  # 500MB (reduced from 1GB)
    num_cpus: 2  # Reduced from 4 to leave room for worker
    temp_dir: /tmp/ray
    include_dashboard: true
    log_to_driver: true
    logging_level: INFO
  
  cluster:
    max_workers: 3  # Reduced from 10 for laptop
    auto_scaling: true
    min_workers: 1
    
  resources:
    memory: 2000000000  # 2GB (reduced from 4GB)
    cpu: 2  # Reduced from 4
    gpu: 0  # Head node typically doesn't need GPU

models:
  preload: ["tiny-gpt2"]  # Only load the smallest model
  cache_dir: "/app/models"

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s" 