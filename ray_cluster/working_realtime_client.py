#!/usr/bin/env python3
"""
Working Real-time Interactive Client for Distributed Ray Cluster
Uses the new coordinator architecture for real inference
"""

import ray
import time
import sys
import os
from datetime import datetime

def working_realtime_client():
    """Working real-time interactive client for distributed inference."""
    
    print("="*80)
    print("ğŸ® [WORKING REALTIME CLIENT] Interactive Distributed Inference")
    print("="*80)
    
    # Connect to the existing Ray cluster
    print("ğŸ”— Connecting to Ray cluster...")
    try:
        ray.init(address='172.18.0.2:6379', ignore_reinit_error=True)
        print("âœ… Connected to Ray cluster")
        print(f"ğŸ“ Cluster resources: {ray.cluster_resources()}")
    except Exception as e:
        print(f"âŒ Failed to connect to Ray cluster: {e}")
        return
    
    print("\nğŸ” [DISCOVERY] Checking cluster status...")
    
    # Get cluster info
    try:
        resources = ray.cluster_resources()
        nodes = [k for k in resources.keys() if k.startswith('node:')]
        print(f"âœ… Found {len(nodes)} nodes in cluster")
        print(f"ğŸ“Š Available resources: {resources}")
    except Exception as e:
        print(f"âš ï¸  Could not get cluster info: {e}")
    
    # Try to get the coordinator
    print("\nğŸ¯ [COORDINATOR] Looking for prompt coordinator...")
    try:
        coordinator = ray.get_actor("prompt_coordinator")
        print("âœ… Found prompt coordinator")
        
        # Get initial actor count
        actor_count = ray.get(coordinator.get_actor_count.remote())
        print(f"ğŸ¤– Available inference actors: {actor_count}")
        
        if actor_count == 0:
            print("âš ï¸  No inference actors available yet")
            print("ğŸ’¡ Wait for worker nodes to join and register their models")
        
    except Exception as e:
        print(f"âŒ Could not find prompt coordinator: {e}")
        print("ğŸ’¡ Make sure the head node is running in coordinator mode")
        return
    
    print("\n" + "="*80)
    print("ğŸ¯ [READY] Real-time inference system ready!")
    print("="*80)
    print("ğŸ’¡ Type your prompts and press Enter to get responses")
    print("ğŸ’¡ Type 'quit' or 'exit' to stop")
    print("ğŸ’¡ Type 'status' to see cluster status")
    print("ğŸ’¡ Type 'actors' to see available inference actors")
    print("ğŸ’¡ Type 'test' to run a test prompt")
    print("ğŸ’¡ Type 'logs' to see recent cluster logs")
    print("="*80)
    
    # Real-time prompt loop
    prompt_count = 0
    
    while True:
        try:
            # Get user input
            prompt = input(f"\nğŸ¤– [PROMPT {prompt_count + 1}] ").strip()
            
            if not prompt:
                continue
                
            if prompt.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ [GOODBYE] Shutting down real-time client...")
                break
                
            if prompt.lower() == 'status':
                print(f"\nğŸ“Š [CLUSTER STATUS]")
                try:
                    resources = ray.cluster_resources()
                    nodes = [k for k in resources.keys() if k.startswith('node:')]
                    print(f"   Nodes: {len(nodes)}")
                    print(f"   CPU: {resources.get('CPU', 0)}")
                    print(f"   Memory: {resources.get('memory', 0) / (1024**3):.1f} GB")
                    print(f"   GPU: {resources.get('GPU', 0)}")
                    
                    # Get actor count
                    actor_count = ray.get(coordinator.get_actor_count.remote())
                    print(f"   Inference Actors: {actor_count}")
                    
                except Exception as e:
                    print(f"   Error getting status: {e}")
                continue
            
            if prompt.lower() == 'actors':
                print(f"\nğŸ¤– [ACTOR STATUS]")
                try:
                    actor_info = ray.get(coordinator.get_actor_info.remote())
                    print(f"   Total Actors: {actor_info['total_actors']}")
                    print(f"   Actor Keys: {actor_info['actor_keys']}")
                    print(f"   Coordinator Node: {actor_info['node_info']['hostname']}")
                except Exception as e:
                    print(f"   Error getting actor info: {e}")
                continue
            
            if prompt.lower() == 'logs':
                print(f"\nğŸ“‹ [RECENT LOGS]")
                print("ğŸ’¡ Check the container logs to see the enhanced logging in action!")
                print("ğŸ’¡ The logs show which node processes each prompt")
                print("ğŸ’¡ Use: docker-compose logs ray-head --tail 10")
                print("ğŸ’¡ Use: docker-compose logs ray-worker-1 --tail 10")
                continue
            
            if prompt.lower() == 'test':
                prompt = "What is artificial intelligence?"
                print(f"ğŸ§ª [TEST PROMPT] Using: '{prompt}'")
            
            # Process the prompt
            print(f"ğŸ“¤ [SENDING] '{prompt}'")
            start_time = time.time()
            
            try:
                # Send to coordinator for real inference
                print(f"ğŸ“¡ [PROCESSING] Sending to coordinator...")
                result = ray.get(coordinator.process_prompt.remote(prompt))
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                # Display results
                print(f"ğŸ“¥ [RESPONSE] (took {processing_time:.2f}s)")
                print(f"ğŸ¤– [ACTORS] Used {result['successful_responses']}/{result['total_actors']} actors")
                
                if result.get('error') == 'NO_ACTORS_AVAILABLE':
                    print(f"âš ï¸  No inference actors available")
                    print(f"ğŸ’¡ Wait for worker nodes to join and register their models")
                else:
                    print(f"ğŸ’¬ [RESPONSE] {result['consolidated_response']}")
                    
                    # Show detailed results if multiple actors
                    if len(result['results']) > 1:
                        print(f"\nğŸ“Š [DETAILED RESULTS]")
                        for i, res in enumerate(result['results']):
                            status = "âœ…" if res['status'] == 'success' else "âŒ"
                            print(f"   {status} Actor {res['actor_id']}: {res['response'][:50]}...")
                
                prompt_count += 1
                
            except Exception as e:
                print(f"âŒ [ERROR] Failed to process prompt: {e}")
                print("ğŸ’¡ Try again or check cluster status with 'status'")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ [GOODBYE] Shutting down real-time client...")
            break
        except EOFError:
            print("\n\nğŸ‘‹ [GOODBYE] Shutting down real-time client...")
            break
    
    # Cleanup
    print("ğŸ§¹ Cleaning up...")
    ray.shutdown()
    print("âœ… Real-time client stopped")

if __name__ == "__main__":
    working_realtime_client() 